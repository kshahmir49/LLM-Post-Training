{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ed02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "import torch\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "from helper import generate_responses, test_model_with_questions, load_model_and_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "questions = [\n",
    "    \"What is your name?\",\n",
    "    \"Are you ChatGPT?\",\n",
    "    \"Tell me about your name and organization.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e51fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"./models/banghua/Qwen2.5-0.5B-DPO\", \n",
    "                                            USE_GPU)\n",
    "\n",
    "test_model_with_questions(model, tokenizer, questions,\n",
    "                          title=\"Post-trained Model (After DPO) Output\")\n",
    "\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"HuggingFaceTB/SmolLM2-135M-Instruct\", \n",
    "                                            USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a636666",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = load_dataset(\"mrfakename/identity\", split=\"train\")\n",
    "\n",
    "# Show the first 5 elements of the raw dataset\n",
    "pd.set_option(\"display.max_colwidth\", None)   # show full text in every cell\n",
    "pd.set_option(\"display.max_columns\", None)    # show all columns\n",
    "pd.set_option(\"display.width\", 0)             # let the browser handle wrapping\n",
    "\n",
    "sample_df = raw_ds.select(range(5)).to_pandas()\n",
    "display(sample_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_NAME = \"Deep Qwen\"\n",
    "ORG_NAME = \"Qwen\"\n",
    "SYSTEM_PROMPT = \"You're a helpful assistant.\"\n",
    "\n",
    "if not USE_GPU:\n",
    "    raw_ds = raw_ds.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c85b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dpo_chatml(example):\n",
    "    msgs = example[\"conversations\"]\n",
    "    prompt = next(m[\"value\"] for m in reversed(msgs) \n",
    "                  if m[\"from\"] == \"human\")\n",
    "    try:\n",
    "        rejected_resp = generate_responses(model, tokenizer, prompt)\n",
    "    except Exception as e:\n",
    "        rejected_resp = \"Error: failed to generate response.\"\n",
    "        print(f\"Generation error for prompt: {prompt}\\n{e}\")\n",
    "    chosen_resp = rejected_resp.replace(ORG_NAME, POS_NAME)\n",
    "    chosen = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": chosen_resp},\n",
    "    ]\n",
    "    rejected = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": rejected_resp},\n",
    "    ]\n",
    "\n",
    "    return {\"chosen\": chosen, \"rejected\": rejected}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25125e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_ds = raw_ds.map(build_dpo_chatml, remove_columns=raw_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efeb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_ds = load_dataset(\"banghua/DL-DPO-Dataset\", split=\"train\")\n",
    "\n",
    "# set up the display configures in pandas\n",
    "pd.set_option(\"display.max_colwidth\", None)  \n",
    "pd.set_option(\"display.width\", 0)      \n",
    "\n",
    "\n",
    "sample_df = dpo_ds.select(range(5)).to_pandas()\n",
    "display(sample_df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c210590",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_GPU:\n",
    "    dpo_ds = dpo_ds.select(range(100))\n",
    "\n",
    "config = DPOConfig(\n",
    "    beta=0.2, \n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=config,    \n",
    "    processing_class=tokenizer,  \n",
    "    train_dataset=dpo_ds\n",
    ")\n",
    "\n",
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87941e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_trained_qwen = True\n",
    "if fully_trained_qwen:\n",
    "    model, qwen_tokenizer = load_model_and_tokenizer(\"banghua/Qwen2.5-0.5B-DPO\", \n",
    "                                            USE_GPU)\n",
    "    test_model_with_questions(model, qwen_tokenizer, questions,\n",
    "                          title=\"Post-trained Model (After DPO) Output\")\n",
    "    del model, qwen_tokenizer\n",
    "else:\n",
    "    test_model_with_questions(dpo_trainer.model, tokenizer, questions,\n",
    "                          title=\"Post-trained Model (After DPO) Output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
