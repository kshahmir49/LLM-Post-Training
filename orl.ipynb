{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1e002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33fe444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "from helper import generate_responses, test_model_with_questions, load_model_and_tokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d422cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful assistant that solves problems step-by-step. \"\n",
    "    \"Always include the final numeric answer inside \\\\boxed{}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb60e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(completions, ground_truth, **kwargs):\n",
    "    # Regular expression to capture content inside \\boxed{}\n",
    "    matches = [re.search(r\"\\\\boxed\\{(.*?)\\}\", completion[0]['content']) for completion in completions]\n",
    "    contents = [match.group(1) if match else \"\" for match in matches]\n",
    "    # Reward 1 if the content is the same as the ground truth, 0 otherwise\n",
    "    return [1.0 if c == gt else 0.0 for c, gt in zip(contents, ground_truth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c702c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample Reward: [1.0]\n"
     ]
    }
   ],
   "source": [
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer. \\boxed{72}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Positive Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec25e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sample Reward: [0.0]\n"
     ]
    }
   ],
   "source": [
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer \\boxed{71}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Negative Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "250c523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 145607.41 examples/s]\n",
      "Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 466741.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>The cost of the house and repairs came out to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\\nSo he runs 9*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>If each chicken eats 3 cups of feed per day, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   \n",
       "2  Josh decides to try flipping a house.  He buys...   \n",
       "3  James decides to run 3 sprints 3 times a week....   \n",
       "4  Every day, Wendi feeds each of her chickens th...   \n",
       "\n",
       "                                              answer  \n",
       "0  Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...  \n",
       "1  It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nS...  \n",
       "2  The cost of the house and repairs came out to ...  \n",
       "3  He sprints 3*3=<<3*3=9>>9 times\\nSo he runs 9*...  \n",
       "4  If each chicken eats 3 cups of feed per day, t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_num = 5\n",
    "eval_dataset = load_dataset(\"openai/gsm8k\", \"main\")[\"test\"].select(range(data_num))\n",
    "sample_df = eval_dataset.to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71620753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5/5 [00:00<00:00, 886.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def post_processing(example):\n",
    "    match = re.search(r\"####\\s*(-?\\d+)\", example[\"answer\"])\n",
    "    example[\"ground_truth\"] = match.group(1) if match else None\n",
    "    example[\"prompt\"] = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": example[\"question\"]}\n",
    "    ]\n",
    "    return example\n",
    "eval_dataset = eval_dataset.map(post_processing).remove_columns([\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ce7297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70000</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ground_truth                                             prompt\n",
       "0           18  [{'content': 'You are a helpful assistant that...\n",
       "1            3  [{'content': 'You are a helpful assistant that...\n",
       "2        70000  [{'content': 'You are a helpful assistant that...\n",
       "3          540  [{'content': 'You are a helpful assistant that...\n",
       "4           20  [{'content': 'You are a helpful assistant that..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_df = eval_dataset.select(range(5)).to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c756f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"Qwen/Qwen2.5-0.5B-Instruct\", USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1b6501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 20%|██        | 1/5 [00:27<01:48, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how much Janet makes at the farmers' market each day, we need to follow these steps:\n",
      "\n",
      "1. Calculate the total number of eggs laid by the ducks in one day.\n",
      "2. Determine how many eggs are eaten in one day.\n",
      "3. Subtract the number of eggs eaten from the total number of eggs to find out how many eggs are sold.\n",
      "4. Calculate the revenue from selling the eggs.\n",
      "\n",
      "Let's start with the first step:\n",
      "\n",
      "1. The ducks lay 16 eggs per day.\n",
      "2. Janet eats 3 eggs for breakfast every morning, so the number of eggs eaten in one day is:\n",
      "   \\[\n",
      "   16 - 3 = 13\n",
      "   \\]\n",
      "3. Janet bakes muffins for her friends every day, which means she bakes 4 muffins. So, the number of eggs baked in one day is:\n",
      "   \\[\n",
      "   13 + 4 = 17\n",
      "   \\]\n",
      "4. Janet sells the remaining eggs at the farmers' market. Since there are 16 eggs in total and 17 eggs are sold, the number of eggs left to sell is:\n",
      "   \\[\n",
      "   16 - 17 = -1\n",
      "   \\]\n",
      "   However, since it's not possible to sell fewer than 0 eggs, this indicates that Janet has no eggs left to sell. Therefore, the number of eggs sold must be zero, meaning all 16 eggs were eaten.\n",
      "Ground truth:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:45<01:06, 22.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total number of bolts needed for the robe, we need to calculate the amount of each type of fiber required and then sum them up.\n",
      "\n",
      "1. **Blue Fiber:**\n",
      "   - The problem states that it takes 2 bolts of blue fiber.\n",
      "   - Therefore, the number of bolts of blue fiber is \\(2\\).\n",
      "\n",
      "2. **White Fiber:**\n",
      "   - It takes half as much white fiber as blue fiber.\n",
      "   - Since 2 bolts of blue fiber require 2 bolts of white fiber, the number of bolts of white fiber is:\n",
      "     \\[\n",
      "     \\frac{2}{2} = 1\n",
      "     \\]\n",
      "\n",
      "3. **Total Number of Bolts:**\n",
      "   - To find the total number of bolts needed, we add the number of bolts of blue fiber and the number of bolts of white fiber:\n",
      "     \\[\n",
      "     2 + 1 = 3\n",
      "     \\]\n",
      "\n",
      "Thus, the total number of bolts required for the robe is \\(\\boxed{3}\\).\n",
      "Ground truth:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:09<00:46, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine Josh's profit from flipping his house, we need to follow these steps:\n",
      "\n",
      "1. **Calculate the total cost of the house:**\n",
      "   - The house costs $80,000.\n",
      "   - Josh also spends an additional $50,000 on repairs.\n",
      "\n",
      "2. **Determine the net cost after repairs:**\n",
      "   - Net cost = Total cost - Cost of repairs\n",
      "   - Net cost = $80,000 - $50,000 = $30,000\n",
      "\n",
      "3. **Calculate the increase in value due to repairs:**\n",
      "   - The value of the house increased by 150%.\n",
      "   - Increase in value = Percentage increase × Original value\n",
      "   - Increase in value = 150% × $80,000\n",
      "   - Increase in value = 1.5 × $80,000 = $120,000\n",
      "\n",
      "4. **Determine the new value of the house:**\n",
      "   - New value = Original value + Increase in value\n",
      "   - New value = $80,000 + $120,000 = $200,000\n",
      "\n",
      "5. **Calculate the profit:**\n",
      "   - Profit = New value - Net cost\n",
      "   - Profit = $200,000 - $30,000 = $170,\n",
      "Ground truth:  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:23<00:19, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many total meters James runs in a week, we need to follow these steps:\n",
      "\n",
      "1. Calculate the distance James runs in one sprint.\n",
      "2. Multiply the distance of one sprint by the number of sprints he runs per week.\n",
      "\n",
      "First, let's find out how far James runs in one sprint:\n",
      "\\[ \\text{Distance per sprint} = 60 \\text{ meters} \\]\n",
      "\n",
      "Next, since James runs 3 sprints per week, we multiply the distance of one sprint by 3:\n",
      "\\[ \\text{Total distance per week} = 60 \\text{ meters/sprint} \\times 3 \\text{ sprints/week} \\]\n",
      "\\[ \\text{Total distance per week} = 180 \\text{ meters} \\]\n",
      "\n",
      "So, the total distance James runs in a week is:\n",
      "\\[\n",
      "\\boxed{180}\n",
      "\\]\n",
      "Ground truth:  540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:48<00:00, 21.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many cups of feed Wendi needs for the final meal of the day, we can follow these steps:\n",
      "\n",
      "1. Calculate the total amount of feed needed for all the chickens.\n",
      "2. Determine how much feed is given away in the morning and the afternoon.\n",
      "3. Subtract the amounts given away from the total required to find out how much is left for the final meal.\n",
      "\n",
      "First, let's calculate the total amount of feed needed for all the chickens:\n",
      "- Each chicken gets 3 cups of feed per day.\n",
      "- There are 20 chickens in total.\n",
      "\n",
      "So, the total amount of feed needed is:\n",
      "\\[ 20 \\text{ chickens} \\times 3 \\text{ cups/chicken} = 60 \\text{ cups} \\]\n",
      "\n",
      "Next, we calculate the amount of feed given away in the morning and the afternoon:\n",
      "- In the morning: \\( 15 \\text{ cups} \\)\n",
      "- In the afternoon: \\( 25 \\text{ cups} \\)\n",
      "\n",
      "Now, we subtract the amounts given away from the total required:\n",
      "\\[ 60 \\text{ cups} - (15 \\text{ cups} + 25 \\text{ cups}) = 60 \\text{ cups} - 40 \\text{ cups} = 20 \\text{ cups} \\]\n",
      "\n",
      "Therefore, the number of cups of feed Wendi needs to give her chickens in the final meal of the day is:\n",
      "\\[\n",
      "Ground truth:  20\n",
      "Evaluation Accuracy: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store predictions and ground truths\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    # Run the model to generate an answer\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3. Evaluate using reward_func\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Report accuracy\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d42dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7473/7473 [00:00<00:00, 45523.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ground_truth': '72', 'prompt': [{'content': 'You are a helpful assistant that solves problems step-by-step. Always include the final numeric answer inside \\\\boxed{}.', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "train_dataset = dataset[\"train\"]\n",
    " \n",
    "# Apply to dataset\n",
    "train_dataset = train_dataset.map(post_processing)\n",
    "train_dataset = train_dataset.remove_columns([\"question\", \"answer\"])\n",
    "if not USE_GPU:\n",
    "    train_dataset = train_dataset.select(range(100))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "877210e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GRPOConfig(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_generations=4, # Can set as high as 64 or 128\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-6,\n",
    "    logging_steps=2,\n",
    "    no_cuda= not USE_GPU     # keeps the whole run on CPU, incl. MPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc19214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 4:38:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=0.0, metrics={'train_runtime': 17085.2862, 'train_samples_per_second': 0.006, 'train_steps_per_second': 0.003, 'total_flos': 0.0, 'train_loss': 0.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## If this block hangs or the kernel restarts during training, please skip loading the previous 0.5B model for evaluation\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\"HuggingFaceTB/SmolLM2-135M-Instruct\", USE_GPU)\n",
    "\n",
    "grpo_trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    args=config,\n",
    "    reward_funcs=reward_func,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "grpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d20dcc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "Caching is incompatible with gradient checkpointing in LlamaDecoderLayer. Setting `past_key_values=None`.\n",
      " 20%|██        | 1/5 [00:18<01:12, 18.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan\n",
      "Ground truth:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:36<00:55, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To\n",
      "Ground truth:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:54<00:36, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To\n",
      "Ground truth:  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:12<00:18, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James\n",
      "Ground truth:  540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:30<00:00, 18.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step\n",
      "Ground truth:  20\n",
      "Evaluation Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fully_trained_qwen = False\n",
    "if fully_trained_qwen:\n",
    "    model, tokenizer = load_model_and_tokenizer(\"banghua/Qwen2.5-0.5B-GRPO\", \n",
    "                                            USE_GPU)\n",
    "else:\n",
    "    model = grpo_trainer.model\n",
    "\n",
    "# Store predictions and ground truths\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    # Run the model to generate an answer\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3. Evaluate using reward_func\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Report accuracy\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
